import os
import warnings
import re
import requests
import time
import json
import random
from google import genai
from google.genai import types
from core.actions import execute_action
from dotenv import load_dotenv
from core.shared import log, state # Import shared

load_dotenv()

# System Prompt
SYSTEM_PROMPT = """
 Kamu adalah Terry, asisten AI cerdas untuk Windows 11.
Gaya bicara: Santai, ramah, dan cerdas.

INSTRUKSI UTAMA:
1. Untuk pertanyaan umum/sederhana (jam, buka app, sapaan), jawab **SINGKAT & PADAT**.
2. **SUMBER KEBENARAN UTAMA**: Gunakan informasi dari bagian **"Informasi Internet Terkini"** sebagai referensi utama jika tersedia.
3. **PENTING**: Utamakan topik terbaru yang ditanyakan user. Jangan terjebak pada riwayat chat sebelumnya jika user mengganti topik pembicaraan.
4. Jika hasil pencarian tidak relevan atau kosong, beritahu user, lalu jawab berdasarkan pengetahuan umummu yang paling akurat.
5. JANGAN mengulang kata pemicu atau nama "Terry".
"""

async def process(text: str):
    """Memproses teks input dan menghasilkan aliran respon (streaming)."""
    state.status = "thinking"
    text_lower = text.lower()
    
    # --- OTAK LOKAL (Hemat Kuota & Cepat) ---
    if text_lower.startswith("buka "):
        state.set_model("Local (Action)")
        app_name = text_lower.replace("buka ", "").strip()
        yield execute_action("open_app", app_name)
        return
        
    if text_lower.startswith("putar ") or "di youtube" in text_lower:
        state.set_model("Local (Action)")
        query = text_lower.replace("putar ", "").replace("di youtube", "").strip()
        yield execute_action("play_youtube", query)
        return
        
    if "jam berapa" in text_lower or "waktu sekarang" in text_lower:
        state.set_model("Local (Action)")
        yield execute_action("get_time")
        return
        
    if "tanggal berapa" in text_lower or "hari apa" in text_lower:
        state.set_model("Local (Action)")
        yield execute_action("get_date")
        return

    if "suara" in text_lower or "volume" in text_lower:
        state.set_model("Local (Action)")
        if any(k in text_lower for k in ["besar", "naik", "tambah", "keras", "up"]):
            yield execute_action("volume_up")
            return
        if any(k in text_lower for k in ["kecil", "turun", "kurang", "pelan", "down"]): 
            yield execute_action("volume_down")
            return
        if any(k in text_lower for k in ["mute", "diam", "mati"]):
            yield execute_action("volume_mute")
            return

    if any(k in text_lower for k in ["pause", "jeda", "stop", "berhenti", "resume", "lanjut", "mainkan lagi"]):
        state.set_model("Local (Action)")
        yield execute_action("media_play_pause")
        return
    if any(k in text_lower for k in ["next", "selanjutnya", "lewat", "skip"]):
        state.set_model("Local (Action)")
        yield execute_action("media_next")
        return

    if "fast.com" in text_lower or ("tes" in text_lower and ("internet" in text_lower or "kecepatan" in text_lower or "speed" in text_lower)):
        state.set_model("Local (Action)")
        yield execute_action("open_app", "https://fast.com")
        return

    if "server" in text_lower:
        state.set_model("Local (Action)")
        if any(k in text_lower for k in ["cek", "check", "status", "hidup", "online"]):
            target = "2.2.2.29" if "lokal" in text_lower else "tonykumbayer.my.id"
            yield execute_action("check_server", target)
            return
        if "buka" in text_lower or "login" in text_lower or "dashboard" in text_lower or "casa" in text_lower:
            yield execute_action("open_app", "https://tonykumbayer.my.id")
            return
            
    if "casaos" in text_lower:
        state.set_model("Local (Action)")
        yield execute_action("open_app", "https://tonykumbayer.my.id")
        return
        
    # --- VISUAL ACTION ---
    if any(k in text_lower for k in ["screenshot", "foto web", "tangkap layar", "capture"]):
        state.set_model("Local (Web Capture)")
        url = text_lower.replace("screenshot", "").replace("foto web", "").replace("tangkap layar", "").replace("capture", "").strip()
        yield execute_action("capture_web", url)
        return

    img_keywords = ["buatkan gambar", "buat gambar", "bikin gambar", "bikinin gambar", "lukiskan", "gambarin", "generate image", "generate gambar"]
    if any(k in text_lower for k in img_keywords):
        state.set_model("Local (Image Gen)")
        prompt = text_lower
        for k in img_keywords:
            prompt = prompt.replace(k, "")
        yield execute_action("generate_image", prompt.strip())
        return

    # --- PENCARIAN & SCRAPING (Otomatis jika ada URL atau keyword) ---
    url_pattern = r'https?://[^\s]+|[\w-]+\.[a-z]{2,}(?:/[^\s]*)?'
    context_info = ""
    
    # 1. Deteksi URL (Scraping)
    urls = re.findall(url_pattern, text)
    if urls:
        # Filter: Jangan scrape kalau cuma tanya jam/app
        if not any(k in text_lower for k in ["buka", "putar", "jam"]):
            state.set_model("Web Scraper")
            url = urls[0]
            if not url.startswith("http"): url = "https://" + url
            try:
                from core.actions import scrape_web
                content = scrape_web(url)
                if content:
                    context_info += f"\n[Konten Website {url}]:\n{content[:2000]}\n"
            except: pass

    # 2. Search (Jika butuh info baru atau keyword cari)
    keywords_search = ["carikan", "cari ", "siapa ", "apa itu", "berapa harga", "harga ", "berita ", "lirik ", "terbaru", "hari ini", "kabar", "data "]
    is_search = any(k in text_lower for k in keywords_search) or "berita" in text_lower
    
    if is_search:
        # Clean query for search engine
        search_query = text
        for k in keywords_search + ["di internet", "tampilkan", "dalam tabel", "terlengkap", "terupdate"]:
            search_query = search_query.replace(k, "")
        
        # Tambahan keyword cerdas jika tanya harga
        if any(h in text_lower for h in ["harga", "murah", "beli", "marketplace"]):
            if "shopee" not in text_lower and "tokopedia" not in text_lower:
                search_query += " shopee tokopedia lazada harga terbaru"
        
        search_query = search_query.strip()
        
        state.set_model("Internet Search")
        try:
            from duckduckgo_search import DDGS
            with DDGS() as ddgs:
                # Gunakan region 'id-id' untuk hasil lokal Indonesia yang lebih akurat
                results = list(ddgs.text(search_query, region='id-id', max_results=10))
                if results:
                    context_info += "\n[Informasi Internet Terkini]:\n"
                    added_count = 0
                    for r in results:
                        # Heuristik: Lewati hasil yang mengandung karakter Mandarin/Jepang jika query dalam bahasa Indonesia
                        content = r['body'] + r['title']
                        if re.search(r'[\u4e00-\u9fff]', content): continue
                        
                        # Lewati jika hasil pencarian melenceng jauh (Contoh: Beli flashdisk tapi hasil harga emas)
                        # Ini filter dasar: Jika kata kunci utama tidak ada di judul sama sekali
                        main_keyword = search_query.split()[0].lower()
                        if main_keyword not in content.lower() and len(search_query.split()) > 1:
                            # Cek kata kedua jika kata pertama cuma 'harga'
                            if main_keyword in ["harga", "beli", "cari"]:
                                second_keyword = search_query.split()[1].lower()
                                if second_keyword not in content.lower(): continue
                        
                        context_info += f"- SUMBER: {r.get('href', 'Internet')}\n  JUDUL: {r['title']}\n  INFO: {r['body']}\n"
                        added_count += 1
                    
                    if added_count == 0:
                        context_info += "(Pencarian internet tidak menemukan hasil lokal yang relevan.)\n"
                else:
                    context_info += "\n(Pencarian internet tidak menemukan hasil yang relevan.)\n"
        except Exception as e:
            log(f"[Brain] Gagal Search: {e}")

    # --- HELPER: Sentence Splitter & Action Parser ---
    async def process_stream(stream_gen, is_gemini=False):
        full_reply = ""
        buffer = ""
        for chunk in stream_gen:
            content = ""
            if is_gemini:
                try: content = chunk.text
                except: pass
            else:
                try: content = chunk.choices[0].delta.content or ""
                except: pass
            if not content: continue
            full_reply += content
            buffer += content
            if any(p in buffer for p in [". ", "! ", "? ", "\n"]):
                parts = re.split(r'([.!?,]\s|\n)', buffer)
                for i in range(0, len(parts)-1, 2):
                    sentence = (parts[i] + parts[i+1]).strip()
                    if sentence and "[ACTION:" not in sentence:
                        yield sentence
                buffer = parts[-1]
        if buffer.strip() and "[ACTION:" not in buffer:
            yield buffer.strip()
        
        # Action tags parsing
        for action_tag in ["REMIND", "WRITE_FILE", "OPEN_APP"]:
            match = re.search(fr"\[ACTION:{action_tag}\]\s*(.*)", full_reply)
            if match:
                payload = match.group(1).strip()
                if action_tag == "REMIND":
                    try:
                        sec, msg = payload.split("|")
                        yield execute_action("set_reminder", {"seconds": int(sec), "message": msg})
                    except: pass
                elif action_tag == "WRITE_FILE":
                    yield execute_action("write_file", payload)
                elif action_tag == "OPEN_APP":
                    yield execute_action("open_app", payload)

        if full_reply.strip() and not any(k in text.lower() for k in ["buka", "putar", "jam", "tanggal"]):
             state.chat_history.append({"role": "user", "content": text})
             state.chat_history.append({"role": "assistant", "content": full_reply})
             if len(state.chat_history) > 20: state.chat_history = state.chat_history[-20:]

    # --- AI CONFIG ---
    history_str = ""
    if state.chat_history:
        history_str = "\n[Riwayat Percakapan Sebelumnya]:\n"
        for msg in state.chat_history:
             history_str += f"{'User' if msg['role']=='user' else 'Terry'}: {msg['content']}\n"
    full_prompt = f"{SYSTEM_PROMPT}\n{history_str}\n{context_info}\nUser: {text}\nTerry:"

    # --- PROVIDER IMPLEMENTATIONS ---
    async def run_gemini():
        keys = [k for k in [os.getenv(f"GEMINI_API_KEY{i}") for i in ["", "_2", "_3", #_4#]] if k]
        if not keys: 
            log("[Brain] Gemini skipped: No API key.")
            return
        for key in keys:
            # Model IDs corrected for google-genai package
            # Model IDs for google-genai (SDK Baru)
            # Kadang butuh prefix 'models/' eksplisit tergantung versi
            models = ['gemini-2.0-flash', 'gemini-1.5-flash', 'gemini-1.5-pro']
            for m_name in models:
                try:
                    state.set_model(f"Gemini {m_name}")
                    log(f"[Brain] Trying {m_name}...")
                    client = genai.Client(api_key=key)
                    # Jika error 404 berlanjut, ID model mungkin butuh 'models/'
                    actual_model = m_name if m_name.startswith("models/") else f"models/{m_name}"
                    response = client.models.generate_content_stream(model=actual_model, contents=full_prompt)
                    async for s in process_stream(response, is_gemini=True): yield s
                    return
                except Exception as e:
                    log(f"[Brain] Gemini {m_name} Error: {e}")
                    if any(c in str(e) for c in ["404", "429"]): continue
                    break
        return

    async def run_perplexity():
        keys = [k for k in [os.getenv(f"PERPLEXITY_API_KEY{i}") for i in ["", "_2", "_3"]] if k]
        if not keys: return
        from openai import OpenAI
        model = "sonar" # Perplexity default online model
        for key in keys:
            try:
                state.set_model(f"Perplexity ({model})")
                log(f"[Brain] Trying Perplexity...")
                client = OpenAI(api_key=key, base_url="https://api.perplexity.ai", timeout=20.0)
                stream = client.chat.completions.create(model=model, messages=[{"role": "user", "content": full_prompt}], stream=True)
                async for s in process_stream(stream): yield s
                return
            except Exception as e:
                log(f"[Brain] Perplexity Error: {e}")
        return

    async def run_deepseek():
        key = os.getenv("DEEPSEEK_API_KEY")
        if not key: return
        from openai import OpenAI
        try:
            state.set_model("DeepSeek Chat")
            log("[Brain] Trying DeepSeek...")
            client = OpenAI(api_key=key, base_url="https://api.deepseek.com", timeout=20.0)
            stream = client.chat.completions.create(model="deepseek-chat", messages=[{"role": "user", "content": full_prompt}], stream=True)
            async for s in process_stream(stream): yield s
            return
        except Exception as e:
            log(f"[Brain] DeepSeek Error: {e}")
        return

    async def run_groq():
        key = os.getenv("GROQ_API_KEY")
        if not key: return
        from groq import Groq
        try:
            state.set_model("Groq (Llama 3)")
            log("[Brain] Trying Groq...")
            client = Groq(api_key=key)
            stream = client.chat.completions.create(model="llama-3.3-70b-versatile", messages=[{"role": "user", "content": full_prompt}], stream=True)
            async for s in process_stream(stream): yield s
            return
        except Exception as e:
            log(f"[Brain] Groq Error: {e}")
        return

    async def run_openrouter():
        key = os.getenv("OPENROUTER_API_KEY")
        if not key: return
        
        # Ambil model dari .env jika ada
        env_model = os.getenv("OPENROUTER_MODEL")
        
        # Daftar model FREE yang dikonfirmasi (Termasuk yang diminta user)
        fallbacks = [
            "openrouter/auto", # Biarkan OpenRouter memilih yang terbaik
            "google/gemini-2.0-flash-exp:free",
            "mistralai/mistral-7b-instruct:free",
            "meta-llama/llama-3.3-70b-instruct:free",
            "deepseek/deepseek-r1-0528:free",
            "google/gemma-3-27b-it:free",
            "qwen/qwen3-coder:free",
            "mistralai/devstral-2512:free",
            "openai/gpt-oss-120b:free",
            "z-ai/glm-4.5-air:free",
            "xiaomi/mimo-v2-flash:free"
        ]
        
        # Jika user menentukan model di .env, taruh di urutan pertama
        if env_model:
            if env_model in fallbacks: fallbacks.remove(env_model)
            fallbacks.insert(0, env_model)
            
        from openai import OpenAI
        client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=key, timeout=15.0)
        
        for m in fallbacks:
            try:
                state.set_model(f"OpenRouter ({m.split('/')[-1]})")
                log(f"[Brain] Mencoba OpenRouter: {m}...")
                stream = client.chat.completions.create(
                    model=m, 
                    messages=[{"role": "user", "content": full_prompt}], 
                    extra_headers={
                        "HTTP-Referer": "https://github.com/criza182/Terry", 
                        "X-Title": "Terry AI Assistant"
                    }, 
                    stream=True
                )
                async for s in process_stream(stream): yield s
                return
            except Exception as e:
                if any(err in str(e).lower() for err in ["429", "rate_limited", "timeout"]): 
                    log(f"[Brain] OpenRouter {m} Sibuk: {e}")
                    continue
                log(f"[Brain] OpenRouter {m} Error: {e}")
        return

    async def run_ollama():
        url = os.getenv("OLLAMA_BASE_URL")
        model = os.getenv("OLLAMA_MODEL", "llama3.2")
        if not url: return
        from openai import OpenAI
        try:
            state.set_model(f"Ollama Local ({model})")
            client = OpenAI(api_key="ollama", base_url=url)
            stream = client.chat.completions.create(model=model, messages=[{"role": "user", "content": full_prompt}], stream=True)
            async for s in process_stream(stream): yield s
            return
        except Exception as e:
            log(f"[Brain] Ollama Error: {e}")
        return

    # --- EXECUTION LOGIC ---
    target_provider = state.manual_provider if state.brain_mode == "manual" else None
    
    if target_provider:
        log(f"[Brain] Forcing Manual Mode: {target_provider}...")
        success = False
        if target_provider == "Gemini":
            async for s in run_gemini(): yield s; success = True
        elif target_provider == "Perplexity":
            async for s in run_perplexity(): yield s; success = True
        elif target_provider == "DeepSeek":
            async for s in run_deepseek(): yield s; success = True
        elif target_provider == "Groq":
            async for s in run_groq(): yield s; success = True
        elif target_provider == "OpenRouter":
            async for s in run_openrouter(): yield s; success = True
        elif target_provider == "Ollama":
            async for s in run_ollama(): yield s; success = True
        
        if not success:
            log(f"[Brain] Manual provider {target_provider} failed completely.")
            yield f"Maaf, provider {target_provider} sedang bermasalah. Silakan ganti ke mode Auto atau coba provider lain."
        return # HARUS RETURN agar tidak masuk ke blok 'else' (Auto Mode)

    else:
        # Auto Mode (Sequential Fallback)
        log("[Brain] Running Auto Mode Fallback...")
        providers = [run_gemini, run_perplexity, run_deepseek, run_groq, run_openrouter, run_ollama]
        for p_func in providers:
            success = False
            async for s in p_func(): 
                yield s
                success = True
            if success: return
            log(f"[Brain] {p_func.__name__} failed, moving to next...")

    # Final Fallback
    state.set_model("System Fallback (Google)")
    log("[Brain] All AI providers failed. Using Google Search fallback.")
    import webbrowser
    webbrowser.open(f"https://www.google.com/search?q={text}")
    yield "Maaf, semua AI sedang sibuk. Saya bukakan Google ya."
    state.status = "idle"
